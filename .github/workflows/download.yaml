name: 'download models'

on:
  workflow_dispatch:
    inputs:
      model:
        required: true
        type: string
        description: 'Model name to be downloaded'
      site:
        required: false
        type: choice
        options:
          - ms
          - hf
        default: 'ms'
        description: 'The site from which the model will be downloaded'
      image:
        required: true
        type: choice
        options:
          - m.daocloud.io/quay.io/ascend/cann:8.1.rc1-910b-ubuntu22.04-py3.10
        default: 'ascendai/cann:8.0.0-910b-ubuntu22.04-py3.10'
        description: 'The docker image which will be loaded'

defaults:
  run:
    shell: bash -el {0}

jobs:
  test:
    name: download models
    runs-on: linux-arm64-npu-0
    container:
      image: ${{ github.event.inputs.image || 'ascendai/cann:8.0.0-910b-ubuntu22.04-py3.10' }}
      env:
        HF_ENDPOINT: https://hf-mirror.com
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
        HF_TOKEN2: ${{ secrets.HF_TOKEN2 }}
        MS_TOKEN: ${{ secrets.MS_TOKEN }}

    steps:
      - name: Config mirrors
        run: |
          sed -i 's|ports.ubuntu.com|mirrors.tuna.tsinghua.edu.cn|g' /etc/apt/sources.list
          pip config set global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple

      - name: Install dependencies
        run: |
          pip install modelscope
          pip install huggingface_hub

      - name: Download from modelscope (manual trigger)
        if: github.event.inputs.site == 'ms'
        run: |
          echo "Triggered manually: downloading model ${{ inputs.model }}"
          modelscope download --model ${{ inputs.model }}

      - name: Download from hf
        if: github.event.inputs.site == 'hf'
        run: |
          echo "Downloading model ${{ inputs.model }} from Hugging Face"
          hf download ${{ inputs.model }} --local-dir /root/.cache/weights/DeepSeek-V3.1-Base

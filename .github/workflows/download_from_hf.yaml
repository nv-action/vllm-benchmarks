#
# Copyright (c) 2025 Huawei Technologies Co., Ltd. All Rights Reserved.
# This file is a part of the vllm-ascend project.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
name: 'e2e test / pd-disaggregation'

on:
  schedule:
    # Runs at 23:00 UTC (7:00 AM Beijing) every day
    - cron: '0 23 * * *'
  pull_request:
    types: [ labeled ]

# Bash shells do not use ~/.profile or ~/.bashrc so these shells need to be explicitly
# declared as "shell: bash -el {0}" on steps that need to be properly activated.
# It's used to activate ascend-toolkit environment variables.
defaults:
  run:
    shell: bash -el {0}

# only 1 job can runs on static-8-01-cards
concurrency:
  group: static-8-01-cards
  cancel-in-progress: false

jobs:
  prefilling-decoding-disaggregation:
    # pd-test will be triggered when tag 'pd-test' & 'ready-for-test' or schedule job
    if: ${{ contains(github.event.pull_request.labels.*.name, 'pd-test') && contains(github.event.pull_request.labels.*.name, 'ready-for-test') || github.event_name == 'schedule' }}
    strategy:
      matrix:
        vllm_verison: [
            main, 
            v0.9.1
          ]
    name: vLLM Ascend prefilling decoding disaggregation test
    runs-on: linux-arm64-npu-static-8

    container:
      image: swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/cann:8.2.rc1-910b-ubuntu22.04-py3.11
      volumes:
        - /usr/local/dcmi:/usr/local/dcmi
        - /usr/local/bin/npu-smi:/usr/local/bin/npu-smi
        - /usr/local/Ascend/driver/:/usr/local/Ascend/driver/
        # Use self-host cache speed up pip and model download
        - /home/action/.cache:/github/home/.cache/
      options: >-
        --device /dev/davinci0
        --device /dev/davinci1
        --device /dev/davinci_manager
        --device /dev/devmm_svm
        --device /dev/hisi_hdc
      env:
        VLLM_USE_MODELSCOPE: True
    steps:
      - name: Config mirrors
        run: |
          pip config set global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple

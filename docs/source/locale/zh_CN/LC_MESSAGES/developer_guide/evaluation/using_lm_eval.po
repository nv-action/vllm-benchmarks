# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-ascend team
# This file is distributed under the same license as the vllm-ascend
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version:  vllm-ascend\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-02-10 09:26+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.18.0\n"

#: ../../source/developer_guide/evaluation/using_lm_eval.md:1
msgid "Using lm-eval"
msgstr "使用 lm-eval"

#: ../../source/developer_guide/evaluation/using_lm_eval.md:3
#, fuzzy
msgid "This document guides you to conduct accuracy testing using [lm-eval][1]."
msgstr ""
"本文将指导你如何使用 [lm-eval](https://github.com/EleutherAI/lm-evaluation-harness)"
" 进行准确率测试。"

#: ../../source/developer_guide/evaluation/using_lm_eval.md:5
msgid "Online Server"
msgstr ""

#: ../../source/developer_guide/evaluation/using_lm_eval.md:7
msgid "1. Start the vLLM server"
msgstr ""

#: ../../source/developer_guide/evaluation/using_lm_eval.md:9
#, fuzzy
msgid "You can run docker container to start the vLLM server on a single NPU:"
msgstr "你可以在单个NPU上运行docker容器："

#: ../../source/developer_guide/evaluation/using_lm_eval.md:38
msgid "The vLLM server is started successfully, if you see logs as below:"
msgstr ""

#: ../../source/developer_guide/evaluation/using_lm_eval.md:46
#: ../../source/developer_guide/evaluation/using_lm_eval.md:167
#, fuzzy
msgid "2. Run GSM8K using lm-eval for accuracy testing"
msgstr "2. 使用 lm-eval 运行 ceval 准确性测试"

#: ../../source/developer_guide/evaluation/using_lm_eval.md:48
msgid "You can query the result with input prompts:"
msgstr ""

#: ../../source/developer_guide/evaluation/using_lm_eval.md:75
msgid "The output format matches the following:"
msgstr ""

#: ../../source/developer_guide/evaluation/using_lm_eval.md:105
#: ../../source/developer_guide/evaluation/using_lm_eval.md:169
#, fuzzy
msgid "Install lm-eval in the container:"
msgstr "在容器中安装 lm-eval。"

#: ../../source/developer_guide/evaluation/using_lm_eval.md:112
#: ../../source/developer_guide/evaluation/using_lm_eval.md:176
msgid "Run the following command:"
msgstr "运行以下命令："

#: ../../source/developer_guide/evaluation/using_lm_eval.md:123
#, fuzzy
msgid "After 30 minutes, the output is as shown below:"
msgstr "1-2 分钟后，输出如下所示："

#: ../../source/developer_guide/evaluation/using_lm_eval.md:135
msgid "Offline Server"
msgstr ""

#: ../../source/developer_guide/evaluation/using_lm_eval.md:137
msgid "1. Run docker container"
msgstr "1. 运行 docker 容器"

#: ../../source/developer_guide/evaluation/using_lm_eval.md:139
msgid "You can run docker container on a single NPU:"
msgstr "你可以在单个NPU上运行docker容器："

#: ../../source/developer_guide/evaluation/using_lm_eval.md:187
#, fuzzy
msgid "After 1 to 2 minutes, the output is shown below:"
msgstr "1-2 分钟后，输出如下所示："

#: ../../source/developer_guide/evaluation/using_lm_eval.md:199
msgid "Use Offline Datasets"
msgstr ""

#: ../../source/developer_guide/evaluation/using_lm_eval.md:201
msgid ""
"Take GSM8K (single dataset) and MMLU (multi-subject dataset) as examples,"
" and you can see more from [here][2]."
msgstr ""

#: ../../source/developer_guide/evaluation/using_lm_eval.md:215
msgid "Set [gsm8k.yaml][3] as follows:"
msgstr ""

#: ../../source/developer_guide/evaluation/using_lm_eval.md:278
msgid "Set [_default_template_yaml][4] as follows:"
msgstr ""

#: ../../source/developer_guide/evaluation/using_lm_eval.md:301
msgid "You can see more usage on [Lm-eval Docs][5]."
msgstr ""

#~ msgid ""
#~ "You can see more usage on [Lm-"
#~ "eval Docs](https://github.com/EleutherAI/lm-evaluation-"
#~ "harness/blob/main/docs/README.md)."
#~ msgstr ""
#~ "你可以在 [Lm-eval 文档](https://github.com/EleutherAI"
#~ "/lm-evaluation-harness/blob/main/docs/README.md) "
#~ "上查看更多用法。"

